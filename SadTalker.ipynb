{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverhe2026888-sys/Cloudflare-dhz/blob/main/SadTalker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdq6j4E5KQAR"
      },
      "outputs": [],
      "source": [
        "#@title **setup（about 5 minutes）**\n",
        "!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.8 2\n",
        "!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.9 1\n",
        "!python --version\n",
        "!apt-get update\n",
        "!apt install software-properties-common\n",
        "!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n",
        "!apt-get install python3-pip\n",
        "\n",
        "print('Git clone project and install requirements...')\n",
        "!git clone https://github.com/cedro3/SadTalker.git &> /dev/null\n",
        "%cd SadTalker\n",
        "!export PYTHONPATH=/content/SadTalker:$PYTHONPATH\n",
        "!python3.8 -m pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!apt update\n",
        "!apt install ffmpeg &> /dev/null\n",
        "!python3.8 -m pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDw3_UN8K2xa"
      },
      "outputs": [],
      "source": [
        "#@title **download model（about 1 minute)**\n",
        "print('Download pre-trained models...')\n",
        "!rm -rf checkpoints\n",
        "!bash scripts/download_models.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **inference for face**\n",
        "image ='full3.png' #@param {type:\"string\"}\n",
        "audio ='eluosi.wav' #@param {type:\"string\"}\n",
        "source_image = 'examples/source_image/' + image\n",
        "driven_audio = 'examples/driven_audio/' + audio\n",
        "\n",
        "!python3.8 inference.py --driven_audio $driven_audio \\\n",
        "           --source_image $source_image \\\n",
        "           --result_dir ./results --enhancer gfpgan"
      ],
      "metadata": {
        "id": "8PXViz3LUiYy",
        "outputId": "b8a271bb-93dd-4cd9-b731-541306439353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ Problematic line not found in /content/SadTalker/src/utils/croper.py, perhaps already fixed or file differs.\n",
            "Available example images:\n",
            "art_0.png   art_14.png\tart_19.png  art_4.png  art_9.png\thappy1.png\n",
            "art_10.png  art_15.png\tart_1.png   art_5.png  full3.png\thappy.png\n",
            "art_11.png  art_16.png\tart_20.png  art_6.png  full4.jpeg\tpeople_0.png\n",
            "art_12.png  art_17.png\tart_2.png   art_7.png  full_body_1.png\tsad1.png\n",
            "art_13.png  art_18.png\tart_3.png   art_8.png  full_body_2.png\tsad.png\n",
            "✅ 文件检查通过，开始生成！\n",
            "   图片: /content/SadTalker/examples/source_image/full3.png\n",
            "   音频: /content/man_audio.mp3\n",
            "using safetensor as default\n",
            "3DMM Extraction for source image\n",
            "landmark Det:: 100% 1/1 [00:00<00:00,  9.56it/s]\n",
            "3DMM Extraction In Video:: 100% 1/1 [00:00<00:00,  9.77it/s]\n",
            "mel:: 100% 3056/3056 [00:00<00:00, 49187.02it/s]\n",
            "audio2exp:: 100% 306/306 [00:00<00:00, 451.10it/s]\n",
            "Face Renderer::  78% 1188/1528 [12:19<03:35,  1.58it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **play movie**\n",
        "import glob\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os, sys\n",
        "\n",
        "# get the last from results\n",
        "mp4_name = sorted(glob.glob('./results/*.mp4'))[-1]\n",
        "\n",
        "mp4 = open('{}'.format(mp4_name),'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "print('Display animation: {}'.format(mp4_name), file=sys.stderr)\n",
        "display(HTML(\"\"\"\n",
        "  <video width=256 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url))"
      ],
      "metadata": {
        "id": "VfnFVzmybpfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **inference for portrait**\n",
        "image ='full3.png' #@param {type:\"string\"}\n",
        "audio ='eluosi.wav' #@param {type:\"string\"}\n",
        "source_image = 'examples/source_image/' + image\n",
        "driven_audio = 'examples/driven_audio/' + audio\n",
        "\n",
        "!python3.8 inference.py --driven_audio $driven_audio \\\n",
        "           --source_image $source_image \\\n",
        "           --result_dir ./results --still --preprocess full --enhancer gfpgan"
      ],
      "metadata": {
        "id": "lTses8gLVYoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **play movie**\n",
        "import glob\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os, sys\n",
        "\n",
        "# get the last from results\n",
        "mp4_name = sorted(glob.glob('./results/*.mp4'))[-1]\n",
        "\n",
        "mp4 = open('{}'.format(mp4_name),'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "print('Display animation: {}'.format(mp4_name), file=sys.stderr)\n",
        "display(HTML(\"\"\"\n",
        "  <video width=256 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url))"
      ],
      "metadata": {
        "id": "KOGCqUaib4CR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "db5031b3636a3f037ea48eb287fd3d023feb9033aefc2a9652a92e470fb0851b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}